{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz71fPGrpRiQ"
      },
      "source": [
        "# An Introduction to Federated Learning\n",
        "\n",
        "Welcome to the Flower federated learning tutorial!\n",
        "\n",
        "In this notebook, we'll build a federated learning system using Flower and PyTorch. In part 1, we use PyTorch for the model training pipeline and data loading. In part 2, we continue to federate the PyTorch-based pipeline using Flower.\n",
        "\n",
        "> Join the Flower community on Slack to connect, ask questions, and get help: [Join Slack](https://flower.dev/join-slack) 🌻 We'd love to hear from you in the `#introductions` channel! If anything is unclear, head over to the `#questions` channel.\n",
        "\n",
        "Let's get stated!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBu1HRRY6bwX"
      },
      "source": [
        "## Step 0: Preparation\n",
        "\n",
        "Before we begin with any actual code, let's make sure that we have everything we need."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4KiTMTpiort"
      },
      "source": [
        "### Installing dependencies\n",
        "\n",
        "Next, we install the necessary packages for PyTorch (`torch` and `torchvision`) and Flower (`flwr`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTrCL2FmC5U5"
      },
      "outputs": [],
      "source": [
        "!pip install -q flwr[simulation] torch torchvision matplotlib #check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UFT3_A3iz76"
      },
      "source": [
        "Now that we have all dependencies installed, we can import everything we need for this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tja2N6l-qH-e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on cpu using PyTorch 1.13.1+cpu and Flower 1.1.0\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "\n",
        "import flwr as fl\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from flwr.common import Metrics\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D2bnPKG58Gx"
      },
      "source": [
        "It is possible to switch to a runtime that has GPU acceleration enabled (on Google Colab: `Runtime > Change runtime type > Hardware acclerator: GPU > Save`). Note, however, that Google Colab is not always able to offer GPU acceleration. If you see an error related to GPU availability in one of the following sections, consider switching back to CPU-based execution by setting `DEVICE = torch.device(\"cpu\")`. If the runtime has GPU acceleration enabled, you should see the output `Training on cuda`, otherwise it'll say `Training on cpu`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVcgAAiaihnx"
      },
      "source": [
        "\n",
        "### Loading the data\n",
        "\n",
        "Federated learning can be applied to many different types of tasks across different domains. In this tutorial, we introduce federated learning by training a simple convolutional neural network (CNN) on the popular CIFAR-10 dataset. CIFAR-10 can be used to train image classifiers that distinguish between images from ten different classes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tpk_Zv37ONm"
      },
      "outputs": [],
      "source": [
        "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toxAoOq6fS2h"
      },
      "source": [
        "We simulate having multiple datasets from multiple organizations (also called the \"cross-silo\" setting in federated learning) by splitting the original CIFAR-10 dataset into multiple partitions. Each partition will represent the data from a single organization. We're doing this purely for experimentation purposes, in the real world there's no need for data splitting because each organization already has their own data (so the data is naturally partitioned).\n",
        "\n",
        "Each organization will act as a client in the federated learning system. So having ten organizations participate in a federation means having ten clients connected to the federated learning server:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9LhPFDh0S5c"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01Zy7yjBPhQd"
      },
      "source": [
        "\n",
        "Let's now load the CIFAR-10 training and test set, partition them into ten smaller datasets (each split into training and validation set), and wrap the resulting partitions by creating a PyTorch `DataLoader` for each of them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4Em7BPNTXeX"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "def load_datasets():\n",
        "    # Download and transform CIFAR-10 (train and test)\n",
        "    transform = transforms.Compose(\n",
        "      [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
        "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
        "\n",
        "    # Split training set into 10 partitions to simulate the individual dataset\n",
        "    partition_size = len(trainset) // NUM_CLIENTS\n",
        "    lengths = [partition_size] * NUM_CLIENTS\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBp7kB4G0sPB"
      },
      "source": [
        "We now have a list of ten training sets and ten validation sets (`trainloaders` and `valloaders`) representing the data of ten different organizations. Each `trainloader`/`valloader` pair contains 4500 training examples and 500 validation examples. There's also a single `testloader` (we did not split the test set). Again, this is only necessary for building research or educational systems, actual federated learning systems have their data naturally distributed across multiple partitions.\n",
        "\n",
        "Let's take a look at the first batch of images and labels in the first training set (i.e., `trainloaders[0]`) before we move on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3dag9WeT9VH"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(trainloaders[0]))\n",
        "\n",
        "# Reshape and convert images to a NumPy array\n",
        "# matplotlib requires images with the shape (height, width, 3)\n",
        "images = images.permute(0, 2, 3, 1).numpy()\n",
        "# Denormalize\n",
        "images = images/2 + 0.5\n",
        "\n",
        "# Create a figure and a grid of subplots\n",
        "fig, axs = plt.subplots(4, 8, figsize=(12, 6))\n",
        "\n",
        "# Loop over the images and plot them\n",
        "for i, ax in enumerate(axs.flat):\n",
        "    ax.imshow(images[i])\n",
        "    ax.set_title(CLASSES[labels[i]])\n",
        "    ax.axis('off')\n",
        "\n",
        "# Show the plot\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGVGbRZ_yEA2"
      },
      "source": [
        "The output above shows a random batch of images from the first `trainloader` in our list of ten `trainloaders`. It also prints the labels associated with each image (i.e., one of the ten possible labels we've seen above). If you run the cell again, you should see another batch of images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TW4Pzb7p1F9"
      },
      "source": [
        "## Step 1: Centralized Training with PyTorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTjCmmBtqPgM"
      },
      "source": [
        "Next, we're going to use PyTorch to define a simple convolutional neural network. This introduction assumes basic familiarity with PyTorch, so it doesn't cover the PyTorch-related aspects in full detail. If you want to dive deeper into PyTorch, we recommend [*DEEP LEARNING WITH PYTORCH: A 60 MINUTE BLITZ*](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYks8IpJL6iK"
      },
      "source": [
        "### Defining the model\n",
        "\n",
        "We use the simple CNN described in the [PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a-convolutional-neural-network):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X3cVBXMpP6w"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCRhau5cr2Gd"
      },
      "source": [
        "Let's continue with the usual training and test functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIl8NfAFpyam"
      },
      "outputs": [],
      "source": [
        "def train(net, trainloader, epochs: int, verbose=False):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDDxh73Sszck"
      },
      "source": [
        "### Training the model\n",
        "\n",
        "We now have all the basic building blocks we need: a dataset, a model, a training function, and a test function. Let's put them together to train the model on the dataset of one of our organizations (`trainloaders[0]`). This simulates the reality of most machine learning projects today: each organization has their own data and trains models only on this internal data: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdUTb8WgtRMz"
      },
      "outputs": [],
      "source": [
        "trainloader = trainloaders[0]\n",
        "valloader = valloaders[0]\n",
        "net = Net().to(DEVICE)\n",
        "\n",
        "for epoch in range(5):\n",
        "    train(net, trainloader, 1)\n",
        "    loss, accuracy = test(net, valloader)\n",
        "    print(f\"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}\")\n",
        "\n",
        "loss, accuracy = test(net, testloader)\n",
        "print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhLGLdmhOhVr"
      },
      "source": [
        "Training the simple CNN on our CIFAR-10 split for 5 epochs should result in a test set accuracy of about 41%, which is not good, but at the same time, it doesn't really matter for the purposes of this tutorial. The intent was just to show a simplistic centralized training pipeline that sets the stage for what comes next - federated learning!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6HP2cYCsqxD"
      },
      "source": [
        "## Step 2: Federated Learning with Flower\n",
        "\n",
        "Step 1 demonstrated a simple centralized training pipeline. All data was in one place (i.e., a single `trainloader` and a single `valloader`). Next, we'll simulate a situation where we have multiple datasets in multiple organizations and where we train a model over these organizations using federated learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf-cW093MzeT"
      },
      "source": [
        "### Updating model parameters\n",
        "\n",
        "In federated learning, the server sends the global model parameters to the client, and the client updates the local model with the parameters received from the server. It then trains the model on the local data (which changes the model parameters locally) and sends the updated/changed model parameters back to the server (or, alternatively, it sends just the gradients back to the server, not the full model parameters).\n",
        "\n",
        "We need two helper functions to update the local model with parameters received from the server and to get the updated model parameters from the local model: `set_parameters` and `get_parameters`. The following two functions do just that for the PyTorch model above.\n",
        "\n",
        "The details of how this works are not really important here (feel free to consult the PyTorch documentation if you want to learn more). In essence, we use `state_dict` to access PyTorch model parameter tensors. The parameter tensors are then converted to/from a list of NumPy ndarray's (which Flower knows how to serialize/deserialize):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZxGk6AMNvvV"
      },
      "outputs": [],
      "source": [
        "### 모델 매개변수 업데이트\n",
        "\n",
        "# 연합 학습에서 서버는 전역 모델 매개변수를 클라이언트에 보내고 클라이언트는 서버에서 받은 매개변수로 로컬 모델을 업데이트합니다. \n",
        "# 그런 다음 로컬 데이터에서 모델을 훈련하고(모델 매개변수를 로컬로 변경) 업데이트/변경된 모델 매개변수를 다시 서버로 보냅니다(또는 전체 모델 매개변수가 아닌 기울기만 서버로 다시 보냅니다)\n",
        "# 서버에서 받은 매개변수로 로컬 모델을 업데이트하고 로컬 모델에서 업데이트된 모델 매개변수를 가져오려면\n",
        "# `set_parameters` 및 `get_parameters`라는 두 가지 도우미 함수가 필요합니다. \n",
        "# 다음 두 함수는 위의 PyTorch 모델에 대한 작업을 수행합니다.\n",
        "# 이것이 어떻게 작동하는지에 대한 자세한 내용은 여기에서 실제로 중요하지 않습니다(자세한 내용을 보려면 PyTorch 설명서를 참조하십시오). \n",
        "# 본질적으로 우리는 `state_dict`를 사용하여 PyTorch 모델 매개변수 텐서에 액세스합니다. 그런 다음 매개변수 텐서는 다음 목록으로/에서 변환됩니다.\n",
        "# NumPy ndarray(꽃이 직렬화/역직렬화하는 방법을 알고 있음):\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]: #get from client\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]): #send to client\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lCf3oljdClM"
      },
      "source": [
        "### Implementing a Flower client\n",
        "\n",
        "With that out of the way, let's move on to the interesting part. Federated learning systems consist of a server and multiple clients. In Flower, we create clients by implementing subclasses of `flwr.client.Client` or `flwr.client.NumPyClient`. We use `NumPyClient` in this tutorial because it is easier to implement and requires us to write less boilerplate.\n",
        "\n",
        "To implement the Flower client, we create a subclass of `flwr.client.NumPyClient` and implement the three methods `get_parameters`, `fit`, and `evaluate`:\n",
        "\n",
        "* `get_parameters`: Return the current local model parameters\n",
        "* `fit`: Receive model parameters from the server, train the model parameters on the local data, and return the (updated) model parameters to the server\n",
        "* `evaluate`: Receive model parameters from the server, evaluate the model parameters on the local data, and return the evaluation result to the server\n",
        "\n",
        "We mentioned that our clients will use the previously defined PyTorch components for model training and evaluation. Let's see a simple Flower client implementation that brings everything together:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye6Jt5p3LWtF"
      },
      "outputs": [],
      "source": [
        "### 꽃 클라이언트 구현\n",
        "\n",
        "# 그런 식으로 흥미로운 부분으로 넘어 갑시다. 연합 학습 시스템은 서버와 여러 클라이언트로 구성됩니다. \n",
        "# Flower에서는 `flwr.client.Client` 또는 `flwr.client.NumPyClient`의 하위 클래스를 구현하여 클라이언트를 만듭니다. \n",
        "# 이 튜토리얼에서는 `NumPyClient`를 사용합니다. 구현하기 쉽고 상용구를 적게 작성해야 하기 때문입니다.\n",
        "# Flower 클라이언트를 구현하기 위해 `flwr.client.NumPyClient`의 하위 클래스를 생성하고 `get_parameters`, `fit` 및 `evaluate` 세 가지 메서드를 구현합니다.\n",
        "\n",
        "# * `get_parameters`: 현재 로컬 모델 매개변수 반환\n",
        "# * `fit`: 서버로부터 모델 파라미터를 수신하고, 로컬 데이터로 모델 파라미터를 훈련하고, (업데이트된) 모델 파라미터를 서버로 반환\n",
        "# * `evaluate`: 서버로부터 모델 파라미터를 받아 로컬 데이터에서 모델 파라미터를 평가하고 평가 결과를 서버로 반환\n",
        "\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "# 클래스 `FlowerClient`는 로컬 교육/평가가 수행되는 방법을 정의하고 Flower가 `fit` 및 `evaluate`를 통해 로컬 교육/평가를 호출할 수 있도록 합니다. \n",
        "# `FlowerClient`의 각 인스턴스는 연합 학습 시스템에서 *단일 클라이언트*를 나타냅니다. \n",
        "# 연합 학습 시스템에는 여러 클라이언트가 있으므로(그렇지 않으면 연합할 것이 많지 않음) 각 클라이언트는 고유한 `FlowerClient` 인스턴스로 표시됩니다. \n",
        "# 예를 들어 워크로드에 세 개의 클라이언트가 있는 경우 세 개의 `FlowerClient` 인스턴스가 있습니다. \n",
        "# Flower는 서버가 훈련을 위해 특정 클라이언트를 선택할 때(및 평가를 위해 `FlowerClient.evaluate`) 각 인스턴스에서 `FlowerClient.fit`을 호출합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Heyxd9MfHOTe"
      },
      "source": [
        "Our class `FlowerClient` defines how local training/evaluation will be performed and allows Flower to call the local training/evaluation through `fit` and `evaluate`. Each instance of `FlowerClient` represents a *single client* in our federated learning system. Federated learning systems have multiple clients (otherwise, there's not much to federate), so each client will be represented by its own instance of `FlowerClient`. If we have, for example, three clients in our workload, then we'd have three instances of `FlowerClient`. Flower calls `FlowerClient.fit` on the respective instance when the server selects a particular client for training (and `FlowerClient.evaluate` for evaluation).\n",
        "\n",
        "### Using the Virtual Client Engine\n",
        "\n",
        "In this notebook, we want to simulate a federated learning system with 10 clients on a single machine. This means that the server and all 10 clients will live on a single machine and share resources such as CPU, GPU, and memory. Having 10 clients would mean having 10 instances of `FlowerClient` in memory. Doing this on a single machine can quickly exhaust the available memory resources, even if only a subset of these clients participates in a single round of federated learning.\n",
        "\n",
        "In addition to the regular capabilities where server and clients run on multiple machines, Flower, therefore, provides special simulation capabilities that create `FlowerClient` instances only when they are actually necessary for training or evaluation. To enable the Flower framework to create clients when necessary, we need to implement a function called `client_fn` that creates a `FlowerClient` instance on demand. Flower calls `client_fn` whenever it needs an instance of one particular client to call `fit` or `evaluate` (those instances are usually discarded after use, so they should not keep any local state). Clients are identified by a client ID, or short `cid`. The `cid` can be used, for example, to load different local data partitions for different clients, as can be seen below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkcwggRYOwWN"
      },
      "outputs": [],
      "source": [
        "### 가상 클라이언트 엔진 사용\n",
        "\n",
        "# 이 노트북에서는 단일 시스템에서 10개의 클라이언트가 있는 연합 학습 시스템을 시뮬레이션하려고 합니다. \n",
        "# 즉, 서버와 10개의 클라이언트 모두가 단일 시스템에 상주하고 CPU, GPU 및 메모리와 같은 리소스를 공유합니다. \n",
        "# 10개의 클라이언트가 있다는 것은 메모리에 10개의 `FlowerClient` 인스턴스가 있다는 것을 의미합니다. \n",
        "# 단일 컴퓨터에서 이 작업을 수행하면 이러한 클라이언트의 하위 집합만 연합 학습의 단일 라운드에 참여하는 경우에도 사용 가능한 메모리 리소스가 빠르게 소진될 수 있습니다.\n",
        "\n",
        "# 따라서 Flower는 서버와 클라이언트가 여러 시스템에서 실행되는 일반 기능 외에도 훈련이나 평가에 실제로 필요한 경우에만 `FlowerClient` 인스턴스를 생성하는 특수 시뮬레이션 기능을 제공합니다. \n",
        "# 필요할 때 Flower 프레임워크가 클라이언트를 생성할 수 있도록 하려면 요청 시 `FlowerClient` 인스턴스를 생성하는 `client_fn`이라는 함수를 구현해야 합니다. \n",
        "# Flower는 'fit' 또는 'evaluate'를 호출하기 위해 특정 클라이언트의 인스턴스가 필요할 때마다 'client_fn'을 호출합니다(이러한 인스턴스는 일반적으로 사용 후 폐기되므로 로컬 상태를 유지해서는 안 됩니다). \n",
        "# 클라이언트는 클라이언트 ID 또는 짧은 `cid`로 식별됩니다. 예를 들어 `cid`는 아래에서 볼 수 있는 것처럼 서로 다른 클라이언트에 대한 서로 다른 로컬 데이터 파티션을 로드하는 데 사용할 수 있습니다.\n",
        "\n",
        "def client_fn(cid: str) -> FlowerClient:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "\n",
        "    # Load model\n",
        "    net = Net().to(DEVICE)\n",
        "\n",
        "    # Load data (CIFAR-10)\n",
        "    # Note: each client gets a different trainloader/valloader, so each client\n",
        "    # will train and evaluate on their own unique data\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "\n",
        "    # Create a  single Flower client representing a single organization\n",
        "    return FlowerClient(net, trainloader, valloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axzXSMtlfhXU"
      },
      "source": [
        "### Starting the training\n",
        "\n",
        "We now have the class `FlowerClient` which defines client-side training/evaluation and `client_fn` which allows Flower to create `FlowerClient` instances whenever it needs to call `fit` or `evaluate` on one particular client. The last step is to start the actual simulation using `flwr.simulation.start_simulation`. \n",
        "\n",
        "The function `start_simulation` accepts a number of arguments, amongst them the `client_fn` used to create `FlowerClient` instances, the number of clients to simulate (`num_clients`), the number of federated learning rounds (`num_rounds`), and the strategy. The strategy encapsulates the federated learning approach/algorithm, for example, *Federated Averaging* (FedAvg).\n",
        "\n",
        "Flower has a number of built-in strategies, but we can also use our own strategy implementations to customize nearly all aspects of the federated learning approach. For this example, we use the built-in `FedAvg` implementation and customize it using a few basic parameters. The last step is the actual call to `start_simulation` which - you guessed it - starts the simulation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELNy0-0nfyI2"
      },
      "outputs": [],
      "source": [
        "### 교육 시작\n",
        "\n",
        "# 이제 클라이언트 측 훈련/평가를 정의하는 `FlowerClient` 클래스와 특정 클라이언트에서 `fit` 또는 `evaluate`를 호출해야 할 때마다 \n",
        "# Flower가 `FlowerClient` 인스턴스를 생성할 수 있는 `client_fn` 클래스가 있습니다. \n",
        "# 마지막 단계는 `flwr.simulation.start_simulation`을 사용하여 실제 시뮬레이션을 시작하는 것입니다.\n",
        "\n",
        "# 함수 `start_simulation`은 `FlowerClient` 인스턴스를 생성하는 데 사용되는 `client_fn`, 시뮬레이션할 클라이언트 수(`num_clients`), 연합 학습 라운드 수(`num_rounds`), 전략. \n",
        "# 이 전략은 *Federated Averaging*(FedAvg)과 같은 연합 학습 접근 방식/알고리즘을 캡슐화합니다.\n",
        "\n",
        "# Flower에는 여러 가지 기본 제공 전략이 있지만 자체 전략 구현을 사용하여 연합 학습 접근 방식의 거의 모든 측면을 사용자 지정할 수도 있습니다. \n",
        "# 이 예에서는 내장된 `FedAvg` 구현을 사용하고 몇 가지 기본 매개변수를 사용하여 사용자 정의합니다. \n",
        "# 마지막 단계는 `start_simulation`에 대한 실제 호출입니다. 짐작하셨겠지만 시뮬레이션을 시작합니다.\n",
        "\n",
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "        fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
        "        min_fit_clients=10,  # Never sample less than 10 clients for training\n",
        "        min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
        "        min_available_clients=10,  # Wait until all 10 clients are available\n",
        ")\n",
        "\n",
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = None\n",
        "if DEVICE.type == \"cuda\":\n",
        "  client_resources = {\"num_gpus\": 1}\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_lIXlErb9qN"
      },
      "source": [
        "### Behind the scenes\n",
        "\n",
        "So how does this work? How does Flower execute this simulation?\n",
        "\n",
        "When we call `start_simulation`, we tell Flower that there are 10 clients (`num_clients=10`). Flower then goes ahead an asks the `FedAvg` strategy to select clients. `FedAvg` knows that it should select 100% of the available clients (`fraction_fit=1.0`), so it goes ahead and selects 10 random clients (i.e., 100% of 10).\n",
        "\n",
        "Flower then asks the selected 10 clients to train the model. When the server receives the model parameter updates from the clients, it hands those updates over to the strategy (*FedAvg*) for aggregation. The strategy aggregates those updates and returns the new global model, which then gets used in the next round of federated learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "713CIPfZ0egy"
      },
      "source": [
        "### Where's the accuracy?\n",
        "\n",
        "You may have noticed that all metrics except for `losses_distributed` are empty. Where did the `{\"accuracy\": float(accuracy)}` go?\n",
        "\n",
        "Flower can automatically aggregate losses returned by individual clients, but it cannot do the same for metrics in the generic metrics dictionary (the one with the `accuracy` key). Metrics dictionaries can contain very different kinds of metrics and even key/value pairs that are not metrics at all, so the framework does not (and can not) know how to handle these automatically.\n",
        "\n",
        "As users, we need to tell the framework how to handle/aggregate these custom metrics, and we do so by passing metric aggregation functions to the strategy. The strategy will then call these functions whenever it receives fit or evaluate metrics from clients. The two possible functions are `fit_metrics_aggregation_fn` and `evaluate_metrics_aggregation_fn`.\n",
        "\n",
        "Let's create a simple weighted averaging function to aggregate the `accuracy` metric we return from `evaluate`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQZ7mINF0egy"
      },
      "outputs": [],
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "    \n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gfn2l-OV0egz"
      },
      "source": [
        "The only thing left to do is to tell the strategy to call this function whenever it receives evaluation metric dictionaries from the clients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yed1AI6x0egz"
      },
      "outputs": [],
      "source": [
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=0.5,\n",
        "        min_fit_clients=10,\n",
        "        min_evaluate_clients=5,\n",
        "        min_available_clients=10,\n",
        "        evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhS5mDVt0egz"
      },
      "source": [
        "We now have a full system that performs federated training and federated evaluation. It uses the `weighted_average` function to aggregate custom evaluation metrics and calculates a single `accuracy` metric across all clients on the server side.\n",
        "\n",
        "The other two categories of metrics (`losses_centralized` and `metrics_centralized`) are still empty because they only apply when centralized evaluation is being used. Part two of the Flower tutorial will cover centralized evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umvwX56Of3Cr"
      },
      "source": [
        "## Final remarks\n",
        "\n",
        "Congratulations, you just trained a convolutional neural network, federated over 10 clients! With that, you understand the basics of federated learning with Flower. The same approach you've seen can be used with other machine learning frameworks (not just PyTorch) and tasks (not just CIFAR-10 images classification), for example NLP with Hugging Face Transformers or speech with SpeechBrain.\n",
        "\n",
        "In the next notebook, we're going to cover some more advanced concepts. Want to customize your strategy? Initialize parameters on the server side? Or evaluate the aggregated model on the server side? We'll cover all this and more in the next tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFiBpTmI0egz"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "Before you continue, make sure to join the Flower community on Slack: [Join Slack](https://flower.dev/join-slack/)\n",
        "\n",
        "There's a dedicated `#questions` channel if you need help, but we'd also love to hear who you are in `#introductions`!\n",
        "\n",
        "The [Flower Federated Learning Tutorial - Part 2](https://flower.dev/docs/tutorial/Flower-2-Strategies-in-FL-PyTorch.html) goes into more depth about strategies and all the advanced things you can build with them."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Flower-1-Intro-to-FL-PyTorch.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "6f1e4b995638708d0c3f3901dc2df4bcf5f39594b9ad4ac7da8fe8c1417c25b9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
